{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50259, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2', bos_token='<|startoftext|>',\n",
    "                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"netflix_titles.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "description = df['description']\n",
    "listed_in =df[\"listed_in\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "['tv action & adventure', 'teen tv shows', 'cult movies', 'tv comedies', 'horror movies', 'tv thrillers', 'crime tv shows', 'lgbtq movies', 'stand-up comedy & talk shows', 'comedies', 'action & adventure', 'romantic movies', 'docuseries', 'stand-up comedy', 'music & musicals', 'tv dramas', 'thrillers', 'sports movies', 'anime series', 'korean tv shows', 'children & family movies', 'tv shows', 'international movies', 'classic & cult tv', 'tv mysteries', 'tv sci-fi & fantasy', 'tv horror', \"kids' tv\", 'british tv shows', 'anime features', 'romantic tv shows', 'classic movies', 'independent movies', 'movies', 'documentaries', 'spanish-language tv shows', 'faith & spirituality', 'reality tv', 'international tv shows', 'science & nature tv', 'dramas', 'sci-fi & fantasy']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "listed_in_arr = [ category.strip().lower().split(\",\") for category in listed_in]\n",
    "dist_listed = []\n",
    "temp =set()\n",
    "\n",
    "listed_in_new = []\n",
    "for category in listed_in_arr:\n",
    "    temp_list = []\n",
    "    for sub_cat in category:\n",
    "        temp.add(sub_cat.strip())\n",
    "        temp_list.append(sub_cat.strip())\n",
    "    listed_in_new.append(temp_list)\n",
    "dist_listed = list(temp)\n",
    "\n",
    "\n",
    "print(len(dist_listed))\n",
    "print(dist_listed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(listed_in_new))\n",
    "cat_list_newArr  =[]\n",
    "for cat_list in listed_in_new:\n",
    "    temp_arr = []\n",
    "    for cur_onehot in dist_listed:\n",
    "        issame = False\n",
    "        \n",
    "        for sub_cat_list in cat_list:\n",
    "            if cur_onehot==sub_cat_list:\n",
    "                issame=True\n",
    "                \n",
    "        if issame:\n",
    "            temp_arr.append(1)\n",
    "        else:\n",
    "            temp_arr.append(0)\n",
    "    cat_list_newArr.append(np.array(temp_arr))\n",
    "\n",
    "len(cat_list_newArr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length :  62\n"
     ]
    }
   ],
   "source": [
    "num_of_flags = len(cat_list_newArr[0])\n",
    "max_length = max([len(tokenizer.encode(title.strip())) for title in description])\n",
    "print(\"max_length : \",max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8807"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor of XY After Concatenation: tensor([5, 5, 5, 6, 6, 6])\n",
      "The tensor of YX After Concatenation: tensor([6, 6, 6, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "X = torch.tensor([5, 5, 5])\n",
    "Y = torch.tensor([6, 6, 6])\n",
    "XY = torch.cat((X, Y), 0)\n",
    "YX = torch.cat((Y, X), 0)\n",
    "print('The tensor of XY After Concatenation:', XY)\n",
    "print('The tensor of YX After Concatenation:', YX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_amount =1000\n",
    "max_amount1= 1100\n",
    "\n",
    "train_description, test_description = description[:min_amount],description[min_amount:max_amount1]\n",
    "train_flags , test_flags = cat_list_newArr[:min_amount],cat_list_newArr[min_amount:max_amount1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42])\n",
      "torch.Size([62])\n",
      "torch.Size([104])\n",
      "tensor([50257,  1722,   607,  2988,  1474,    82,   262,   886,   286,   465,\n",
      "         1204,    11, 26479, 39700,   268,  5030,  9539,   465,  1918,   287,\n",
      "        47602,   290,   401,   605,  2842,   284,  1037,   606,  1111,  1986,\n",
      "          262, 13203,    13, 50256, 50258, 50258, 50258, 50258, 50258, 50258,\n",
      "        50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
      "        50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
      "        50258, 50258,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     1,     0,     0,     0,\n",
      "            0,     0,     0,     0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "X = torch.tensor( train_flags[i],dtype=torch.int32)\n",
    "encodings_dict = tokenizer('<|startoftext|>' + train_description[i] + '<|endoftext|>',\n",
    "                                       max_length=max_length, padding=\"max_length\")\n",
    "Y =  torch.tensor(encodings_dict['input_ids'],dtype=torch.int32)\n",
    "print(X.shape)\n",
    "print(Y.shape)                                  \n",
    "XY = torch.cat((Y,X), 0)\n",
    "print(XY.shape)\n",
    "print(XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetflixDataset(Dataset):\n",
    "    def __init__(self, txt_list,flags, tokenizer, max_length,batch_size):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        for txt,cur_flag in zip(txt_list,flags):\n",
    "            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>',\n",
    "                                       max_length=max_length, padding=\"max_length\")\n",
    "            input_ids_X  = torch.tensor(encodings_dict['input_ids'])\n",
    "            cur_flag_tensor = torch.tensor(cur_flag)\n",
    "            input_ids_X_cur_flag = torch.cat((input_ids_X,cur_flag_tensor), 0)\n",
    "            self.input_ids.append(input_ids_X_cur_flag)\n",
    "\n",
    "\n",
    "            attention_mask_X  = torch.tensor(encodings_dict['attention_mask'])\n",
    "            attention_mask_X_cur_flag = torch.cat((attention_mask_X,cur_flag_tensor), 0)\n",
    "            self.attn_masks.append(attention_mask_X_cur_flag)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #input_ids_X_batches = self.input_ids[idx*self.batch_size : (idx+1)*self.batch_size]\n",
    "        #attn_masks_X_batches = self.attn_masks[idx*self.batch_size : (idx+1)*self.batch_size]\n",
    "        \n",
    "        return self.input_ids, self.attn_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NetflixDataset(train_description,train_flags, tokenizer, max_length=max_length,batch_size=8)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50257,  1722,   607,  2988,  1474,    82,   262,   886,   286,   465,\n",
      "         1204,    11, 26479, 39700,   268,  5030,  9539,   465,  1918,   287,\n",
      "        47602,   290,   401,   605,  2842,   284,  1037,   606,  1111,  1986,\n",
      "          262, 13203,    13, 50256, 50258, 50258, 50258, 50258, 50258, 50258,\n",
      "        50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
      "        50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
      "        50258, 50258,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     1,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([2, 104])\n",
      "tensor(50257)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for temp in train_dataset:\n",
    "    print(temp[0][0])\n",
    "    print(temp[1][0])\n",
    "    data = torch.stack([f[0] for f in temp])\n",
    "    print(data.shape)\n",
    "    data = torch.stack([f[1][0] for f in temp])\n",
    "    print(data[0])\n",
    "    break\n",
    "    \"\"\"\n",
    "    if len(temp[0])!=len(temp[1]) and len(temp[0])==62:\n",
    "        print(temp[0])\n",
    "        print(temp[1])\n",
    "    \n",
    "        break\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./results', num_train_epochs=5, logging_steps=100, save_steps=500,\n",
    "                                  per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "                                  warmup_steps=10, weight_decay=0.05, logging_dir='./logs', report_to = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 900\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 900\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64753d612735475e97be2c6c66971128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5685, 'learning_rate': 4.4943820224719104e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0744, 'learning_rate': 3.9325842696629214e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0304, 'learning_rate': 3.370786516853933e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0092, 'learning_rate': 2.8089887640449443e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-500\n",
      "Configuration saved in ./results\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0091, 'learning_rate': 2.2471910112359552e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0226, 'learning_rate': 1.6853932584269665e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0015, 'learning_rate': 1.1235955056179776e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0015, 'learning_rate': 5.617977528089888e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0065, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 55.6422, 'train_samples_per_second': 16.175, 'train_steps_per_second': 16.175, 'train_loss': 0.4137448890341653, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=900, training_loss=0.4137448890341653, metrics={'train_runtime': 55.6422, 'train_samples_per_second': 16.175, 'train_steps_per_second': 16.175, 'train_loss': 0.4137448890341653, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trainer(model=model, args=training_args, train_dataset=train_dataset, \n",
    "        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0][0] for f in data]),\n",
    "                                                              'attention_mask': torch.stack([f[1][0] for f in data]),\n",
    "                                                              'labels': torch.stack([f[0][0] for f in data])}).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampel prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50257,  1722,   607,  2988,  1474,    82,   262,   886,   286,   465,\n",
      "         1204,    11, 26479, 39700,   268,  5030,  9539,   465,  1918,   287,\n",
      "        47602,   290,   401,   605,  2842,   284,  1037,   606,  1111,  1986,\n",
      "          262, 13203,    13, 50256, 50258, 50258, 50258, 50258, 50258, 50258,\n",
      "        50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
      "        50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
      "        50258, 50258,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     1,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "inputS = torch.stack([f[0][0] for f in val_dataset])\n",
    "print(inputS[0])\n",
    "print(len(inputS[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.\n",
      "Generated output :  As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"!!!!!!!!\" (!) \"Avengers: My Father's Bawling & Mother Of Theoms For Our Fathers As People Were In Troubles To Begging Their Ownings And They Still Boarding With A Differently Even though they all love their own\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "X = torch.tensor( train_flags[i])\n",
    "encodings_dict = tokenizer('<|startoftext|>' + train_description[i] + '<|endoftext|>',\n",
    "                                       max_length=max_length, padding=\"max_length\")\n",
    "Y =  torch.tensor(encodings_dict['input_ids'])\n",
    "#print(X.shape)\n",
    "#print(Y.shape)                                  \n",
    "XY = torch.cat((Y,X), 0)\n",
    "\n",
    "sample_input = torch.reshape(XY,(1,-1)).cuda()\n",
    "#print(sample_input)\n",
    "#print(sample_input[0].shape)\n",
    "#print(len(sample_input[0]))\n",
    "\n",
    "sample_outputs = model.generate(sample_input,no_repeat_ngram_size = 1,num_beams=20, num_return_sequences=2,max_new_tokens=50)\n",
    "#print(len(sample_outputs))\n",
    "print(\"Input : \",train_description[i])\n",
    "print(\"Generated output : \",tokenizer.decode(sample_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_flags[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tv action & adventure', 'teen tv shows', 'cult movies', 'tv comedies', 'horror movies', 'tv thrillers', 'crime tv shows', 'lgbtq movies', 'stand-up comedy & talk shows', 'comedies', 'action & adventure', 'romantic movies', 'docuseries', 'stand-up comedy', 'music & musicals', 'tv dramas', 'thrillers', 'sports movies', 'anime series', 'korean tv shows', 'children & family movies', 'tv shows', 'international movies', 'classic & cult tv', 'tv mysteries', 'tv sci-fi & fantasy', 'tv horror', \"kids' tv\", 'british tv shows', 'anime features', 'romantic tv shows', 'classic movies', 'independent movies', 'movies', 'documentaries', 'spanish-language tv shows', 'faith & spirituality', 'reality tv', 'international tv shows', 'science & nature tv', 'dramas', 'sci-fi & fantasy']\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(dist_listed)\n",
    "print(len(dist_listed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t:tv action & adventure\n",
      "0\t:teen tv shows\n",
      "0\t:cult movies\n",
      "0\t:tv comedies\n",
      "0\t:horror movies\n",
      "0\t:tv thrillers\n",
      "0\t:crime tv shows\n",
      "0\t:lgbtq movies\n",
      "0\t:stand-up comedy & talk shows\n",
      "0\t:comedies\n",
      "0\t:action & adventure\n",
      "0\t:romantic movies\n",
      "0\t:docuseries\n",
      "0\t:stand-up comedy\n",
      "0\t:music & musicals\n",
      "0\t:tv dramas\n",
      "0\t:thrillers\n",
      "0\t:sports movies\n",
      "0\t:anime series\n",
      "1\t:korean tv shows\n",
      "0\t:children & family movies\n",
      "0\t:tv shows\n",
      "0\t:international movies\n",
      "0\t:classic & cult tv\n",
      "0\t:tv mysteries\n",
      "0\t:tv sci-fi & fantasy\n",
      "1\t:tv horror\n",
      "0\t:kids' tv\n",
      "0\t:british tv shows\n",
      "0\t:anime features\n",
      "0\t:romantic tv shows\n",
      "0\t:classic movies\n",
      "0\t:independent movies\n",
      "0\t:movies\n",
      "0\t:documentaries\n",
      "0\t:spanish-language tv shows\n",
      "0\t:faith & spirituality\n",
      "0\t:reality tv\n",
      "0\t:international tv shows\n",
      "0\t:science & nature tv\n",
      "0\t:dramas\n",
      "0\t:sci-fi & fantasy\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Scientists conduct research on sharks\"\n",
    "\n",
    "\n",
    "\n",
    "input_flags = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for flag,cat in zip(input_flags,dist_listed):\n",
    "    print(str(flag)+\"\\t:\"+cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X  !!!!!!!!!!!!!!!!!!!\"!!!!!!\"!!!!!!!!!!!!!!!\n",
      "Input :  Scientists conduct research on sharks\n",
      "Generated output :  Scientists conduct research on sharks!!!!!!!!!!!!!!!!!!!\"!!!!!!\"!!!!!!!!!!!!!!!(s) (As her father dies in the end of his life to help them both face their paths together as they go along Their parents battle against other people's cruel and anger towards themselves - all eyes will soon be greeted with a sickeningly\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "X = torch.tensor(input_flags)\n",
    "\n",
    "\n",
    "encodings_dict = tokenizer('<|startoftext|>' + input_text + '<|endoftext|>',\n",
    "                                       max_length=max_length, padding=\"max_length\")\n",
    "Y =  torch.tensor(encodings_dict['input_ids'])    \n",
    "\n",
    "print(\"X \",tokenizer.decode(X, skip_special_tokens=True))\n",
    "XY = torch.cat((Y,X), 0)\n",
    "sample_input = torch.reshape(XY,(1,-1)).cuda()\n",
    "\n",
    "sample_outputs = model.generate(sample_input,no_repeat_ngram_size = 1,num_beams=20, num_return_sequences=2,max_new_tokens=50)\n",
    "print(\"Input : \",input_text)\n",
    "\n",
    "\n",
    "print(\"Generated output : \",tokenizer.decode(sample_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2534928701.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [23]\u001b[1;36m\u001b[0m\n\u001b[1;33m    Generated output :  stranger!!!!!!!!!!!!!!!!!!!!!!\"!!!!!!!!!!!!!!!!!!!!'\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Input :  stranger\n",
    "Generated output :  stranger!!!!!!!!!!!!!!!!!!!!!!\"!!!!!!!!!!!!!!!!!!!!'\n",
    "As her grows his father nears, they come to help them both face the wrath of their captors and provide themselves with a great chance at its own peril. And there will be no one who has everything in my heart as it comes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tharhtet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46ff7e5b8b7911cfa9955e23e477c53e63d207f4b9ab3253a6a5ac7336ecbe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
